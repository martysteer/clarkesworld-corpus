{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f230bd-ef48-4e4a-9e61-d9310531c0b1",
   "metadata": {},
   "source": [
    "## metadata out to CSV\n",
    "\n",
    "Extracts metadata from trafilatura's xml and json conversions of the scraped html files from Clarkesworld.\n",
    "The csv can then be edited, cleaned up manually, and the metadata be put back into the filesystem.\n",
    "#@see meta-in.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deb1a3f8-dbcd-41ce-a27b-e5322e26d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf25b1b4-c0cf-41ee-bcdc-7939b97d6b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/1/21QgJXT6wVnb-zv2by+b1DVhlI4.xml',\n",
       " './data/1/MyOyM9pq+yOEP9mNAfO2VjYVBp4.json',\n",
       " './data/1/+B+tTSkvZzVVhXr1YTtbktWOxhY.json',\n",
       " './data/1/7VkxKi84dUugRxCOaQ3q2e2VBCM.json',\n",
       " './data/1/jIyDx-OHlrPUFTAg5SyvoJX6KEY.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('./data/**/*')\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4579b326-8046-4306-a3a0-b279ffe8914b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('++M+2YuuVIycIfW6FiYV87BbjRA', './data/2/++M+2YuuVIycIfW6FiYV87BbjRA.txt'),\n",
       " ('+3YBUN7z1a90VaWdoXze4QMmcPY', './data/1/+3YBUN7z1a90VaWdoXze4QMmcPY.txt'),\n",
       " ('+3xiKoo7QkBjqEP9MIhtCyxTLCI', './data/1/+3xiKoo7QkBjqEP9MIhtCyxTLCI.xml'),\n",
       " ('+49NksTYUKxEKz8i6xv3zblj1xY', './data/1/+49NksTYUKxEKz8i6xv3zblj1xY.xml'),\n",
       " ('+6uMh33KnQ-w3K3w5H06U1vopDU', './data/1/+6uMh33KnQ-w3K3w5H06U1vopDU.txt')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traf_ids = sorted([(os.path.basename(f).split('.')[0], f) for f in files])\n",
    "traf_ids[:5]\n",
    "\n",
    "# i decided not to output the trafid's into the CSV file. \n",
    "# The fingerprint hash in each trafilatura embedded metadata does match, so I decided to use this to merge/lookup/join etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b14f5a91-adc5-4080-88d9-39abd9650190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 112 ms, total: 1.68 s\n",
      "Wall time: 1.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate dataframe from XML sources\n",
    "frames = []\n",
    "\n",
    "for tid, fn in [f for f in traf_ids if f[1].endswith('xml')]:\n",
    "    frame = pd.read_xml(fn, xpath='//doc', attrs_only=True)\n",
    "    frames.append(frame)\n",
    "\n",
    "meta = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "272df335-da65-4789-9047-e31a2b1fe793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sitename', 'title', 'author', 'date', 'source', 'hostname', 'excerpt',\n",
       "       'categories', 'tags', 'fingerprint'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e512029-69db-434b-9420-847487fe0385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.82 s, sys: 242 ms, total: 5.07 s\n",
      "Wall time: 5.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# generate dataframe from JSON sources\n",
    "frames = []\n",
    "\n",
    "for tid, fn in [f for f in traf_ids if f[1].endswith('json')]:\n",
    "    frame = pd.read_json(fn, lines=True)\n",
    "    del frame['raw_text']\n",
    "    del frame['text']\n",
    "    frames.append(frame)\n",
    "\n",
    "meta = meta.append(pd.concat(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4440a5a3-59ea-4680-b6b0-f5346aa246e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sitename', 'title', 'author', 'date', 'source', 'hostname', 'excerpt',\n",
       "       'categories', 'tags', 'fingerprint', 'id', 'license', 'comments',\n",
       "       'source-hostname'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcadb752-1600-43c1-aa19-aa8ccebf1288",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01272f11-ace8-4cff-9d27-e4540297fad6",
   "metadata": {},
   "source": [
    "### Do some data alterations\n",
    "\n",
    "- Fill empties from eachother's values. (sitename is in traffy's XML, source-hostname in it's JSON)\n",
    "- use 'excerpt' to get story 'title' for all entries.\n",
    "- group by/deduplicate by 'fingerprint'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7a2dc76-8d2d-458c-b60e-2bb1f546268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empties from eachother's values. (sitename is in traffy's XML, source-hostname in it's JSON)\n",
    "meta['sitename'] = meta['sitename'].fillna(value=meta['source-hostname'])\n",
    "meta['source-hostname'] = meta['source-hostname'].fillna(value=meta['sitename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "350e58c3-abea-4e87-9c51-274f2ad3d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 'excerpt' to get story 'title' for all entries.\n",
    "# Some basic pattern matching works for the clarkesworld website <excerpt> strings.\n",
    "titles = meta['excerpt'].str.split('This page: ', expand=True)[1].to_frame()\n",
    "meta['title'] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c266ecfc-9dff-4cd8-b3ae-74ac4c496d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by/deduplicate by 'fingerprint'.\n",
    "meta = meta.drop_duplicates(subset=['fingerprint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d80149-e5c4-4145-8042-e55a950b4ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e12ea042-ddd6-46d1-b792-3bc29168456f",
   "metadata": {},
   "source": [
    "## Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4b87cb1-d2eb-43b1-bcc4-5b8d14f5246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.to_csv('./traffy-meta.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988a066-7c39-4856-a317-e7bcec98a94e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
