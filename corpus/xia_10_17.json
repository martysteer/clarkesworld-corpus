{"fingerprint": "384n6acAprK47IL7yq00vj9OCQ0=", "sitename": "Clarkesworld Magazine", "title": "The Psychology Game by Xia Jia, translated by Emily Jin and Ken Liu", "author": "Xia Jia; Emily Jin; Ken Liu", "date": "2022-01-01", "source": "https://clarkesworldmagazine.com/xia_10_17/", "hostname": "clarkesworldmagazine.com", "excerpt": "Clarkesworld Science Fiction and Fantasy Magazine and Podcast. This page: The Psychology Game by Xia Jia, translated by Emily Jin and Ken Liu", "categories": null, "tags": null, "id": 0, "license": null, "comments": null, "source-hostname": "Clarkesworld Magazine", "text": "2880 words, short story\n The Psychology Game\n This is a globally popular reality TV show.\n The structure of the show is simple. The screen is split in half: on the left, the patient reclines in a sling chair; on the right sits the therapist. To preserve anonymity for both participants, their faces are replaced by vivid software-generated 3D cartoon versions and their voices processed to remove identifying characteristics. Nonetheless, through facial expressions, gestures, poses, and tone, the audience can grasp the total context of the conversation.\n The patient and the therapist are not in the same room (sometimes they may even be on opposites sides of the globe), and the only way for them to speak to each other is through the show\u2019s communication link. Their conversation is live-streamed in its entirety, except for occasional bits of personally identifiable information that are automatically filtered by software. Both participants volunteer to be on the show. The patient receives a fee, enough to pay for the counseling, and the therapist gets to make a name. Although many have raised concerns about the format of the show, it has consistently performed well in the ratings.\n On the show, you hear the most private confessions of other people. You realize that happy people are all alike, but every unhappy person is unhappy in their own way. Step by step you begin to play the role, and you see yourself reflected in those people. You feel that they are voicing doubts and conflicts in your heart that you\u2019ve never been able to put into words. Yes, yes, it\u2019s exactly like that, you say to yourself again and again, what would I do if that happened to me?\n You feel curious, excited, disgusted, angry, frustrated, sympathetic, melancholic, oppressed, fearful, anguished, confused, desperate, ecstatic . . .\n During the broadcast, there is a constantly increasing counter in the lower right corner of the screen, telling the audience how many viewers, struggling with pain, have found courage through this show and managed to seek professional help.\n \n Therapist: Did you say you\u2019ve been feeling unwell?\n \n \n Patient: Yes . . . I think I might be suffering from depression.\n \n \n Therapist: When did it start?\n \n \n Patient: About a month ago.\n \n \n Therapist: What, specifically, has been bothering you?\n \n \n Patient: I\u2019m tired, and I lack energy. Sometimes I stay in bed the whole day, not wanting to get up.\n \n \n Therapist: How\u2019s your sleep?\n \n \n Patient: I wake up every morning around three or four, and then can\u2019t fall asleep again. That\u2019s the worst part.\n \n The most controversial part of the show is a little ritual before every counseling session. The patient is presented with two pills, one red and one blue, and the patient must pick one\u2014an obvious homage to The Matrix. The two pills represent two possible therapists, one an actual, licensed mental health professional, and the other a virtual creation of artificial intelligence software.\n Neither the patient nor the audience knows whether the talking head on the other half of the screen is a human or a machine.\n \n Therapist: Anything else?\n \n \n Patient: Well, I have this unsettling feeling.\n \n \n Therapist: Tell me more about this unsettling feeling.\n \n \n Patient: I just feel . . . very anxious. All sorts of different thoughts run through my brain, and every little thing seems so involved that I don\u2019t want to do anything.\n \n \n Therapist: When you say you don\u2019t want to do anything, is it because of the effort it takes?\n \n \n Patient: It\u2019s not about effort, but because it feels . . . so uninteresting.\n \n \n Therapist: You\u2019ve lost interest in things? \n \n \n Patient: Yes. Eating, shopping, going to the movies . . . everything feels pointless.\n \n \n Therapist: Well, it does sound like you are depressed.\n \n Every episode lasts an hour. During the show, the audience can log in at any point to vote for or against the therapist, and the vote tally is updated live. Therapists whose support falls too low are eliminated from the show.\n However, no one knows if the eliminated therapist is human or machine. For every therapist on the show, the producers provide the audience with a personal profile replete with details\u2014birth date, family history, and a full CV. After every episode, passionate debates erupt online as viewers scrutinize every aspect of those profiles, seizing on the most minor apparent discrepancies. If someone claims to have gone to school with one of the therapists and posts their class photo or snapshots of parties, someone else will jump in the next second to point out signs that the photos are faked. The truth remains ever elusive.\n In 1997, IBM\u2019s Deep Blue chess computer defeated the reigning chess world champion, Garry Kasparov. In 2011, supercomputer Watson, jointly developed by IBM and the University of Texas, defeated two human contestants on the most popular quiz show in America, Jeopardy!. In 2017, a documentary series about an intelligent talking toy called iTalk and its effect on autistic children, \u201cLet\u2019s Have a Talk,\u201d touched the hearts of hundreds of millions around the globe. In 2020, the online livecast reality show \u201cThe Psychology Game,\u201d produced by Microsoft Research Asia and Safer Media once again brought artificial intelligence into the spotlight.\n \n Interviewer: What made you sign up for the show in the first place?\n \n \n Patient: I\u2019d say curiosity, for the most part. I watched a few episodes, thought it was interesting, and decided to sign up and have a go.\n \n \n Interviewer: Have you ever had psychological counseling before?\n \n \n Patient: No. I\u2019ve considered it, but it never got beyond that.\n \n \n Interviewer: Is it because getting counseling still comes with a bit of stigma?\n \n \n Patient: Yeah. Even though nowadays getting counseling is so common\u2014how does that joke go? \u201cIt\u2019s out of the blue for someone to not be blue!\u201d\u2014I still get the jitters when it comes to making an actual appointment with a mental health professional. It\u2019s like that superstition about how there\u2019s nothing wrong with you when you don\u2019t go to the doctor, but as soon as you go, all kinds of problems show up . . . I don\u2019t feel comfortable talking to my family about it either because they\u2019ll worry. And what will others say if they knew I\u2019m getting counseling?\n \n \n Interviewer: But you don\u2019t feel these worries when it\u2019s on TV?\n \n \n Patient: Yeah . . . if I get to be on TV, I don\u2019t care about saving face. Besides, on the show no one can see your real face, you know?\n \n In 1950, the mathematician Alan Turing suggested in his paper \u201cComputing Machinery and Intelligence\u201d a test for whether machines are able to develop the same kind of intelligence as human beings, based on the principle of imitation.\n Imagine a sealed dark room, where a person of common intellect (B) sits next to a machine (A). There is another person outside of the room (C) who feeds a constant stream of questions to A and B, who will provide their answers to C with typed answers on a paper tape. If C is unable to tell A and B apart after several rounds of interrogation, then it seems that we must acknowledge the absence of a fundamental difference between a person and a machine.\n The key to the Turing Test is that there is no rigorous definition of \u201cmind/consciousness/soul.\u201d Turing thus sets aside the question \u201cCan machines think?\u201d and substitutes a more operable question: \u201cCan machines do what we thinking beings can do?\u201d\n But can those two questions really replace each other?\n For example, machines can write poetry, and some machine-generated poems read better than the productions of humans without a talent for poetry. If we devise an artificial set of standards for scoring poems, it\u2019s very possible that we can design a machine whose poetry will score better than the vast majority of humans\u2019. But is this really equivalent to how humans understand and appreciate a poem?\n \n Interviewer: So, being on the show isn\u2019t quite the same as real life, is it?\n \n \n Patient: Right . . . it feels like I\u2019m performing a little bit.\n \n \n Interviewer: Do you mean that what happened on the show was an act?\n \n \n Patient: I wouldn\u2019t go that far. It\u2019s like this: while I talked about my life on TV, I felt like I was also observing myself from the side. I wanted to see what was wrong with this person, why was he so miserable. This feeling got especially strong when I told this sad story\u2014something I\u2019d never told anyone else\u2014suddenly, I felt so empathetic. How on Earth was he able to keep this all to himself, for all those years? Tears started to roll. And before I knew it, I was bawling.\n \n \n Interviewer: Right, I saw that part too.\n \n \n Patient: I wasn\u2019t going to tell the story, and I didn\u2019t plan to cry at all. A complete surprise.\n \n \n Interviewer: Did you feel better after crying it out?\n \n \n Patient: It doesn\u2019t work like that. That was only the start, and I have to learn to face my emotions\u2014the therapist said so.\n \n \n Interviewer: Did you find the therapist helpful?\n \n \n Patient: I really agree with one thing that he said: the cognitive process behind the emotions is more important than the emotions themselves.\n \n \n Interviewer: What does that mean to you?\n \n \n Patient: Let\u2019s take the example of the sad story I told on TV. Everyone feels sad once in a while, right? But at the time when that happened, I forced myself to feel nothing. Everyone thinks that a man can never show that he\u2019s hurt. Even if he\u2019s falling apart, he\u2019s got to stand there and take it. So that\u2019s what I did, but I never forgave myself for it.\n \n \n Interviewer: Is this the cognitive process behind your emotions?\n \n \n Patient: Yes. Deep down, I knew that I wasn\u2019t who I was pretending to be, but I had to keep up the show. Everyone thinks I live a perfect life, but inside, I\u2019ve always felt like a failure.\n \n At an international conference in 2013, Hector Levesque, a computer scientist from the University of Toronto, presented a paper criticizing the Turing Test. He argues that Turing\u2019s human-machine games cannot accurately reflect AI\u2019s level of intelligence. The real challenge for AI is answering certain types of questions:\n Kate said \u201cthank you\u201d to Anna because her warm hug made her feel much better. Who felt better?\n A. KateB. Anna\n Questions like this are based on the linguistic phenomenon of anaphora. To determine the antecedent of \u201cher,\u201d one needs not a grammar textbook, a dictionary, or an encyclopedia, but common sense. How can an AI understand under what circumstance one person would say \u201cthank you\u201d to another? How can an AI know what actions would make one \u201cfeel much better\u201d? These question touch upon the very essence of human language and social interaction, the very areas where AI remains most limited.\n It\u2019s easy to build a robot that can play chess with people, but far harder to create a robot that can understand the losing chess player\u2019s complaints.\n \n Interviewer: Do you think your problems can be resolved?\n \n \n Patient: The therapist says so, but I\u2019ll need time.\n \n \n Interviewer: Do you still want to continue with the counseling sessions then?\n \n \n Patient: Probably, yeah. To be honest, before the show, I didn\u2019t really know what counseling involved. I felt quite repulsed back then\u2014felt like letting someone dissect your brain and inspect the pieces. But therapists don\u2019t have superpowers. They can\u2019t read your mind; you have to tell them what you\u2019re thinking.\n \n \n Interviewer: You mean you don\u2019t feel as repulsed anymore?\n \n \n Patient: Yeah, I\u2019m starting to understand what this is all about.\n \n \n Interviewer: So you would say that this show was useful to you?\n \n \n Patient: Yeah, I didn\u2019t expect that this would happen.\n \n \n Interviewer: May I ask when would be your next counseling session?\n \n \n Patient: I\u2019ve made my appointments already. I\u2019ll go once every week, starting next Tuesday.\n \n \n Interviewer: Will you be seeing the same therapist you met on the show?\n \n \n Patient: Yes, the same one.\n \n \n Interviewer: You\u2019ll see him in person?\n \n \n Patient: No, we\u2019ll use video chat, same as on the show. Even our faces will be masked. It feels more relaxed that way.\n \n In counseling, sometimes the therapist needs to play the role of a neutral, trustworthy listener and companion, but sometimes the therapist needs to engage with the troubling scenario; sometimes they must call upon logos, other times pathos.\n Machines cannot interpret human emotions, but they can learn to use certain procedures to process problems involving emotions. This is not unlike how a machine that does not understand what poems are can still compose passable poetry. From this perspective, it\u2019s possible to conclude that machines can do the job of therapists, because psychological counseling is built on the belief that human emotions can be effectively processed, just like poetry and a lot of other things.\n However, sometimes the urge to solve a problem is also the cause of the problem in the first place. Take insomnia as an example. For some insomniacs, the source of their inability to fall asleep is the desperate craving for sleep. \u201cI can\u2019t fall asleep\u201d and \u201cI really want to sleep\u201d become a mutually-reinforcing cycle of paradox. A machine therapist can tell the patient: \u201cThe reason you can\u2019t fall asleep is because you are too desperate to fall asleep. Take it easy.\u201d But \u201ctake it easy\u201d can\u2019t break the cycle of \u201cI can\u2019t fall asleep\u2014I really want to sleep\u201d because ultimately, trying to \u201ctake it easy,\u201d in this case, is equivalent to \u201cI really want to sleep.\u201d\n The same applies to some cases of depression. Depressed patients are often frustrated by the feeling that they\u2019re failing at \u201cI want to be happy,\u201d which then leads them to ruminate on \u201cwhat can make me happy?\u201d However, asking this very question makes \u201cI want to be happy\u201d an impossible mission. For depressed patients, \u201cI want to be happy\u201d and \u201cI can\u2019t be happy\u201d then become a circular paradox similar to the insomnia cycle. When there\u2019s no distinction between cause and effect, there\u2019s no place to begin the processing.\n Machines cannot process such paradoxes, and humans who are accustomed to machines\u2019 way of thinking are not any better. However, if we can forget about the paradox\u2014forget about the effect, forget about the cause, forget about the ends and the means, forget about \u201cI can\u2019t fall asleep\u201d and \u201cI want to be happy,\u201d even forget about this irksome \u201cI\u201d\u2014then the paradox itself will vanish altogether.\n The Chan Buddhist Master Huineng once said: \u201cThe Bodhi is not a tree, and the mirror does not reflect. In eternal nothingness, how would specks of dust collect?\u201d\n \n Interviewer: One more question\u2014are you ever worried that your therapist might be a machine?\n \n \n Patient: Well, how do I put this\u2014\n \n \n Interviewer: We won\u2019t get into the question of whether machines should be therapists. Let\u2019s focus just on your feelings. Have you ever felt worried, at all?\n \n \n Patient: I guess I don\u2019t think people are any more reliable than machines. We used to question driverless vehicles, question how machines can cook, diagnose patients, and prescribe drugs, but nowadays these things are so commonplace. Machines won\u2019t drink and drive, won\u2019t spit in your food because they are having a bad day, won\u2019t prescribe you expensive brand drugs to get the manufacturer\u2019s kickback. Anyway, I never worry about having machines do these things for me.\n \n \n Interviewer: But isn\u2019t psychological counseling different?\n \n \n Patient: I don\u2019t think it\u2019s that different. People used to oppose AI diagnosticians too. They said that machines can\u2019t empathize, and they don\u2019t know what it means to be in pain or uncomfortable, but then all these objections turned out to be irrelevant. Mental illnesses are illnesses too, and there is a process to be followed. Human or machine, why does it matter\u2014as long as they solve the patient\u2019s problem? And to be honest, human therapists have feelings too. If you keep on unloading your emotional garbage onto them, wouldn\u2019t they suffer too? Sometimes I think using human therapists is kind of inhumane.\n \n \n Interviewer: You mean that it might actually be better if we handed everything over to artificial intelligence?\n \n \n Patient: Depends on which one works better. Technology is always evolving and getting better, and maybe it\u2019s inevitable that machines will replace humans one day.\n \n Perhaps the key to the problem is this: in an era of technological explosion, we are forced to constantly evaluate and distinguish between the kinds of work that absolutely require human judgment, and the kinds of work that can be performed by machines (or are even better when performed by machines). During this process, our pride at our own uniqueness is constantly assaulted. We may ultimately find out that in many situations, a human being is not essential to another human being.\n This will make us anxious, frustrated, or even lead us to plunge down the dark pit of despair, but at the same time, it also forces us to think about what humans really mean to each other\u2014similar to the way each psychological counseling session is also an opportunity to understand ourselves better as we dig into our own emotions and thoughts.\n To date, machines are still unable to answer that oldest of questions, \u201cWhat is human?\u201d Even as everything accelerates around us, we mustn\u2019t forget to turn back and reexamine the oracle from thousands of years ago:\n \u03b3\u03bd\u1ff6\u03b8\u03b9 \u03c3\u03b5\u03b1\u03c5\u03c4\u03cc\u03bd\n Originally published in Chinese in Knowledge is Power, September 2015.\n Translated and published in partnership with Storycom.\n Xia Jia (aka Wang Yao) is Associate Professor of Chinese Literature at Xi'an Jiaotong University and has been publishing speculative fiction since college. She is a seven-time winner of the Galaxy Award, China's most prestigious science fiction award and has published three science fiction collections (in Chinese): The Demon-Enslaving Flask (2012), A Time Beyond Your Reach (2017), and Xi'an City Is Falling Down (2018). Her first English language short story collection, A Summer Beyond Your Reach, will be the first book published by Clarkesworld Books. She's also engaged in other science fiction related works, including academic research, translation, screenwriting, and teaching creative writing.\n Ken Liu is an American author of speculative fiction. A winner of the Nebula, Hugo, and World Fantasy awards, he wrote the Dandelion Dynasty, a silkpunk epic fantasy series (starting with The Grace of Kings), as well as short story collections The Paper Menagerie and Other Stories and The Hidden Girl and Other Stories. He also authored the Star Wars novel The Legends of Luke Skywalker.\n Prior to becoming a full-time writer, Liu worked as a software engineer, corporate lawyer, and litigation consultant. Liu frequently speaks at conferences and universities on a variety of topics, including futurism, cryptocurrency, history of technology, bookmaking, narrative futures, and the mathematics of origami.\n Liu is also the translator for Liu Cixin\u2019s The Three-Body Problem, Hao Jingfang\u2019s \u201cFolding Beijing\u201d and Vagabonds, Chen Qiufan\u2019s Waste Tide, as well as the editor of Invisible Planets and Broken Stars, anthologies of contemporary Chinese science fiction.\n He lives with his family near Boston, Massachusetts.\n Emily Xueni Jin (she/her) is a science fiction and fantasy translator, translating both from Chinese to English and the other way around. She graduated from Wellesley College in 2017, and she is currently pursuing a PhD in East Asian Languages and Literature at Yale University. As one of the core members of the Clarkesworld-Storycom collaborative project on publishing English translations of Chinese science fiction, she has worked with various prominent Chinese SFF writers. Her most recent Chinese to English translations can be found in AI2041: Ten Visions For Our Future, a collection of science fiction and essays co-written by Dr. Kaifu Lee and Chen Qiufan (scheduled to publish September 2021) and The Way Spring Arrives co-published by Tor and Storycom, the first translated female and non-binary Chinese speculative fiction anthology (scheduled to publish April 2022). Her essays can be found in publications such as Vector and Field Guide to Contemporary Chinese Literature."}