Non-Fiction
Countdown to Singularity: A Conversation with Vernor Vinge
The Technological Singularity is a popular trope in science fiction that promises the birth of superhuman intelligence. Whether this entity arises as an artificial intelligence or through the amplification of our own brains, humanity may be forced to radically alter its way of life just to survive.
Vernor Vinge, author of the Hugo Award winning novels Rainbows End, A Fire Upon the Deep, and A Deepness in the Sky, has championed this theory since the 1980s, but it was in a presentation to NASA and a subsequent essay in 1993 that he truly fleshed out his understanding of the Singularity and predicted that one should take place between 2005 and 2030.
“There are [many] people who inspired this,” Vinge says. “In science fiction the notion of big changes, including unknowably big changes, has long been a trope. [In the 1960s] there would be stories about super-intelligent critters and the consequences of dealing with super-intelligence. It wasn’t so much about technological progress as it was about aliens. However, together those different things within science fiction meant that many readers, and certainly myself, had the different pieces of this notion of a Singularity—namely technological change in the relatively near future where the most important change would be the rise of super-intelligence and the consequences of that.”
There are numerous technological developments that might hasten a Singularity, and Vinge thinks that “right now the one that is proceeding like gangbusters is large computer networks and their associated users waking up as a superhumanly intelligent entity.” The 2007 San Diego wildfires and Google’s coverage of the disaster via Google Maps provides an excellent example of these networks. “An immense amount of information was immediately available there. It really involved all sorts of infrastructure. It involved satellites. It involved robot aircrafts. It involved people on the ground taking pictures. And it involved humans actually interacting with it all to generate more information. In fact, it was so good that, as often is the case, the chief question is: Is it true? You get pictures that are so pretty that [whether] they’re true or not slips into the background.”
The abundance of “small, simple devices in the environment” contributes to the increase of human intellect. “I can remember that in the 1960s,” Vinge says, “I very clearly had the notion of Intelligence Amplification—using computer human hookups to achieve greater than human intelligence. But the notion of all sorts of small things in the environment becoming smart, that was something I had not thought about. I can remember how companies wanted to put computers in cameras. I don’t know if that sounds strange anymore, but in 1965 that would be a little bit like saying, ‘Let’s put a giraffe in a camera.’ There’s a question of size compatibility, but to a science fiction reader that shouldn’t be a big deal because we’re familiar with the notion of miniaturization. But there was also the idea of relevance, and I think if you go back far enough into the 20th Century, the relevance of putting a computer in another application didn’t make any sense because people did not realize how the computer could substitute for the moving parts complexity of the device.
“The cell phone on many different levels speaks to trends toward Singularity,” Vinge continues. “The origin of the term depended on a very large support infrastructure, namely the cell towers and the equipment that was in them. If you go back before that, science fiction [writers] wrote about small wireless telephones, but the notion that [the phones] depended on this immense investment in local radio relays—that I don’t think was there. The idea of having this stuff throughout the environment was not high on the radar screen.” Modern advances in cell phone technology lend it further credence as a precursor to a Singularity. Attachments like Bluetooth move society “toward this headband technology that science fiction writers from the early 60s on had in mind. That is Intelligence Amplification plus the notion of people being able to cooperate with other people invisibly, and thus becoming a sort of superhuman entity.”
Despite the proliferation of small computational devices, Vinge thinks that many people, when considering the possible roads to a Singularity, regard the improvement of human intelligence as the most likely course. Vinge imagines a time when “we start getting prosthetics for parts of the brain, and therefore part of the mind. That’s an intriguing possibility because it would be an interesting response to people who can’t imagine a machine having awareness. What happens when we begin to get grayscale cases—that is, people [with significant portions] of their brains [as] these prosthetics? Right now, actually, I think there are some very small components of the brain that people are talking about being able to repair. There are some central connection points deep in the middle of the brain. If those fail, usually you get a vegetable.”
Vinge then dovetails off current medical knowledge to engage in what he calls “serious Vernor speculation.” He observes that often coma patients recover “after an infection that has caused swelling. It raises the possibility in my mind that the trauma that caused the coma had separated things that were supposed to be connected, and the inflammation has brought those areas back in touch with each other. I think it’s not just vast speculation, but people have said more conservative things in the same direction. It’s quite possible that adding small amounts of connectivity could cure some forms of persistent vegetative state. What if artificial vision was able to cure some types of blindness because the neurons in your brain aren’t working right, not because your eyeball isn’t working right?
“We may end up in the medical field [with] a creeping cyberization, or a creeping prosthetization, of mental function. This should be a great interest to people who want to debate these issues about artificial intelligence.”
Though biological science does provide some exciting theorization, in the end Vinge believes biology will fall short because it “amounts to a specific solution on a specific substrate, namely the proteins and DNA. That’s one way of running mind. It seems implausible to me that it’s the most efficient way or the fastest way of running mind. If you look at the entire range of physics and the entire range of environments in the universe, it seems we should find one that can support significantly more powerful, computational methods. In the long run (twenty or thirty years) biology loses.
“One follow-up that is an interesting optimistic point is that even if biology is not the last word, our form of life has an enormous advantage over the machines. We work in situations where the machines don’t work. If there was some terrible disaster that happened to the machines, obviously humans would suffer enormously, but it’s quite likely that not all humans would die. And the humans are capable of rebuilding the machines. So, if you are one of our hypothetical machine-based super-critters, you might be very happy there are humans around because the humans would form the ultimate backup system.
“We have perfect analogies here. As much as some humans may sneer on the biological environment, if all the plants died, you and I would be in deep trouble in a short amount of time. If all the bacteria die, that might be even worse.”
While the many possible roads to the Singularity are great sources of speculation, the creation of artificial intelligence relies on the existence of powerful computer hardware. Vinge says that “raw computer hardware is progressing just fine. Computer hardware trends are moving along embarrassingly and accurately per the trends that were speculated about twenty or thirty years ago. It’s actually kind of eerie. Part of the reason the trends are moving this way is determined by the economic decisions of the manufacturers. They get together and have a roadmap for where we are going to be for the next three or five years, and at least on a timescale of two or three years, they can make good on those. There is an element of self-fulfilling prophecy here.” Vinge references a book entitled Petaflop Computing that discusses “the possibility that we would achieve [the Singularity] by 2014. I really like the book because [it has] these charts about what [the authors] think is going to happen, when and how it’s going to happen. We are ahead of their prognostications.
“If you have those hardware trends, and then if you can estimate the hardware power that we have in our heads, and if you believe that estimate, and if you believe the hardware trends are going to continue (which actually is a type of prediction that may not happen), then that’s a plausibility argument for the Singularity.” But the argument comes up short because we still don’t understand “how to organize the pieces in a way that can support what we think of as thought. Progress in that area I think is proceeding, but if I was going to attack the plausibility of a Singularity as in the essay, that would be the place to attack it.”
Even though Vinge has spent a large part of his career thinking and writing about the Singularity, he does not believe it is inevitable, though he does consider it the “most likely out of the non-catastrophic outcomes of the 21st century. I think there are particular forms of the Singularity that can be as scary as anything you want to think about: for instance, a hard takeoff [a Singularity that manifests in a very short time] as the result of a military arms race, or, even worse, a hard takeoff occurring during a war. On the other hand, in its broader form it is something that is very like what humans have always tried to aim for in terms of making things better and understanding the universe. It is quite possible that it could work out in such a way that ordinary humans would end up being participants.”
It is also possible that the Singularity might happen but human beings would lack the capacity to recognize it. “It is quite plausible,” Vinge says, “that roaches do not recognize humans the way we [recognize] gods. Certainly if there were something superhuman, and if it wanted to convince us of its existence, it could do so.
“If the Singularity does not happen, and there’s no disaster that kills everybody off, then there probably will be unending arguments about whether it has secretly happened somehow. If that’s how things end up, I certainly hope I would not be a person who’s trying to argue it had happened but we just hadn’t noticed it.”
Since April 2005, Shaun Farrell has conducted well over seventy author interviews with some of the biggest names in speculative fiction. He is the producer and cohost of the Adventures in Scifi Publishing podcast (www.adventuresinscifipublishing.com), and in 2007 he turned Paul Levinson's Locus Award winning novel The Silk Code into a podcast novel for distribution through podiobooks.com.